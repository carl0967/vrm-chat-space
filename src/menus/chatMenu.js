import { setStatusText } from "../top_common.js";
import {
  AI_CHARACTER_SYSTEM_PROMPT,
  AI_NAME,
  OPENAI_TTS_CONFIG,
  AIVIS_TTS_CONFIG,
} from "../config.js";
import {
  MIC_PERMISSION_ERROR_CODE,
  MIC_PERMISSION_ERROR_MESSAGE,
} from "../constants/micPermission.js";
import { logMessage } from "../utils/logger.js";

/**
 * ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ä½œæˆã™ã‚‹ã€‚
 * OpenAI APIã‚­ãƒ¼å…¥åŠ›ã€Aivis APIã‚­ãƒ¼å…¥åŠ›ã€éŸ³å£°èªè­˜ã€Speech to Textã€Text to Textï¼ˆChatCompletionï¼‰ã€TTSæ©Ÿèƒ½ã‚’æä¾›ã™ã‚‹ã€‚
 */
export function createChatMenu({
  apiKeyInput,
  aivisApiKeyInput,
  micButton,
  chatTranscript,
  chatStatusElement,
  textInput,
  sendButton,
  ttsAudioPlayer,
  actionMenu,
  vrmManager,
  // Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆè¦ç´ 
  bottomChatMessages,
  bottomChatTextInput,
  bottomChatMicButton,
  bottomChatSendButton,
}) {
  // NOTE: ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰å°‚ç”¨ã§ã™ã€‚menuActiveã¯å¸¸ã«trueã¨ã—ã¦å‹•ä½œã—ã¾ã™ã€‚
  const state = {
    menuActive: true, // ãƒãƒ£ãƒƒãƒˆå°‚ç”¨ã®ãŸã‚å¸¸ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–
    apiKey: "",
    aivisApiKey: "",
    isRecording: false,
    mediaRecorder: null,
    audioChunks: [],
    chatHistory: [], // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ï¼ˆsystemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€userãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€assistantãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
    isProcessing: false, // AIå¿œç­”å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°
    audioElement: null, // TTSéŸ³å£°å†ç”Ÿç”¨ã®AudioElementï¼ˆWebå†ç”Ÿï¼‰
    isSpeaking: false, // TTSéŸ³å£°å†ç”Ÿä¸­ãƒ•ãƒ©ã‚°
    mediaSource: null, // AIVISç”¨ã®MediaSource
    ttsAudioPlayer: ttsAudioPlayer || null,
    recordingSource: null, // éŒ²éŸ³é–‹å§‹å…ƒï¼ˆ"bottomChat" ã¾ãŸã¯ "settingsMenu"ï¼‰
  };

  // sessionStorageã‹ã‚‰APIã‚­ãƒ¼ã‚’å¾©å…ƒ
  const storedOpenAIKey = sessionStorage.getItem("openai_api_key");
  const storedAivisKey = sessionStorage.getItem("aivis_api_key");
  if (storedOpenAIKey && apiKeyInput) {
    apiKeyInput.value = storedOpenAIKey;
  }
  if (storedAivisKey && aivisApiKeyInput) {
    aivisApiKeyInput.value = storedAivisKey;
  }

  /**
   * ãƒã‚¤ã‚¯æ¨©é™ã«ç´ã¥ãã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã€‚
   * @param {Error|DOMException} error - åˆ¤å®šã—ãŸã„ã‚¨ãƒ©ãƒ¼ã€‚
   * @returns {boolean} ãƒã‚¤ã‚¯æ¨©é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ trueã€‚
   */
  function isMicPermissionError(error) {
    if (!error) {
      return false;
    }
    if (error?.code === MIC_PERMISSION_ERROR_CODE) {
      return true;
    }
    const name = error?.name || "";
    if (name === "NotAllowedError" || name === "SecurityError") {
      return true;
    }
    const message = error?.message || "";
    return message.includes("è¨±å¯") || message.includes("denied");
  }

  /**
   * ãƒã‚¤ã‚¯æ¨©é™ã‚¨ãƒ©ãƒ¼ã‚’å…±é€šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå›ºå®šæ–‡è¨€ï¼‰ã«å¤‰æ›ã™ã‚‹ã€‚
   * @param {Error|DOMException} error - æ­£è¦åŒ–ã—ãŸã„ã‚¨ãƒ©ãƒ¼ã€‚
   * @returns {Error} å…±é€šæ–‡è¨€ã®ã‚¨ãƒ©ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã€‚
   */
  function normalizeMicPermissionError(error) {
    if (!isMicPermissionError(error)) {
      return error;
    }
    if (error?.code === MIC_PERMISSION_ERROR_CODE || error?.message === MIC_PERMISSION_ERROR_MESSAGE) {
      return error;
    }
    const wrappedError = new Error(MIC_PERMISSION_ERROR_MESSAGE);
    wrappedError.name = "MicPermissionError";
    wrappedError.code = MIC_PERMISSION_ERROR_CODE;
    wrappedError.cause = error;
    return wrappedError;
  }

  /**
   * ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºã‚’æ›´æ–°ã™ã‚‹ã€‚
   */
  function setChatStatus(text) {
    setStatusText(chatStatusElement, text);
  }

  /**
   * ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢ï¼‰ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ã™ã‚‹ã€‚
   * @param {string} text - è¡¨ç¤ºã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @param {string} speaker - ç™ºè©±è€…ï¼ˆ"user" ã¾ãŸã¯ "ai"ï¼‰
   */
  function appendTranscript(text, speaker = "user") {
    if (!chatTranscript) {
      return;
    }
    const speakerLabel = speaker === "ai" ? AI_NAME : "éŸ³å£°å…¥åŠ›";
    const entry = `${speakerLabel}ï¼š${text}\n`;
    chatTranscript.textContent += entry;
    // è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
    chatTranscript.scrollTop = chatTranscript.scrollHeight;

    // Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢ã«ã¯AIã®ç™ºè¨€ã®ã¿ã‚’è¿½åŠ 
    if (bottomChatMessages && speaker === "ai") {
      const aiEntry = `${AI_NAME}ï¼š${text}`;
      bottomChatMessages.textContent = bottomChatMessages.textContent
        ? `${bottomChatMessages.textContent}\n${aiEntry}`
        : aiEntry;
      // è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
      bottomChatMessages.scrollTop = bottomChatMessages.scrollHeight;
    }
  }

  /**
   * AudioContextã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œä¸­ã«ç¢ºå®Ÿã«ã‚¢ãƒ³ãƒ­ãƒƒã‚¯ã™ã‚‹ã€‚
   * resume() ã‚’è©¦ã—ã€å¿…è¦ã«å¿œã˜ã¦ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡ã‚’å†ç”Ÿã™ã‚‹ã€‚
   * @param {string} triggerLabel - å‘¼ã³å‡ºã—å…ƒã®è­˜åˆ¥å­
   */
  async function ensureAudioContextUnlocked(triggerLabel = "") {
    const audioContext = state.ttsAudioPlayer?.audioListener?.context;
    if (!audioContext) {
      logMessage("Warn", "[ChatMenu] AudioContext unlock: TTSãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼æœªè¨­å®š", { trigger: triggerLabel });
      return;
    }

    if (audioContext.state === "running") {
      return;
    }

    try {
      await audioContext.resume();
    } catch (error) {
      logMessage("Warn", "[ChatMenu] AudioContext resumeå¤±æ•—", { error: error });
    }

    if (audioContext.state === "running") {
      return;
    }

    try {
      // ãƒ–ãƒ©ã‚¦ã‚¶ã®è‡ªå‹•å†ç”Ÿãƒãƒªã‚·ãƒ¼ã§resumeãŒæ‹’å¦ã•ã‚ŒãŸå ´åˆã§ã‚‚AudioContextã‚’ã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œæ¸ˆã¿ã€ã«ã™ã‚‹ãŸã‚ã€
      // çŸ­ã„ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡ã‚’å†ç”Ÿã—ã¦ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¼·åˆ¶çš„ã«ç¢ºç«‹ã™ã‚‹ã€‚
      const durationSeconds = 0.05;
      const frameCount = Math.max(1, Math.floor(audioContext.sampleRate * durationSeconds));
      const silentBuffer = audioContext.createBuffer(1, frameCount, audioContext.sampleRate);
      const source = audioContext.createBufferSource();
      source.buffer = silentBuffer;
      const gain = audioContext.createGain();
      gain.gain.value = 0;
      source.connect(gain);
      gain.connect(audioContext.destination);
      await new Promise((resolve) => {
        source.onended = () => {
          source.disconnect();
          gain.disconnect();
          resolve();
        };
        source.start();
      });
    } catch (silentError) {
      logMessage("Warn", "[ChatMenu] ç„¡éŸ³ãƒãƒƒãƒ•ã‚¡å†ç”Ÿã«å¤±æ•—", { error: silentError });
    }
  }

  /**
   * APIã‚­ãƒ¼ã®å¦¥å½“æ€§ã‚’ç°¡æ˜“ãƒã‚§ãƒƒã‚¯ã™ã‚‹ã€‚
   * OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã€‚Aivis APIã‚­ãƒ¼ã¯ä»»æ„ï¼ˆå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯AIVIS TTSã‚’ä½¿ç”¨ï¼‰ã€‚
   */
  function validateApiKey() {
    state.apiKey = apiKeyInput?.value?.trim() || "";
    state.aivisApiKey = aivisApiKeyInput?.value?.trim() || "";

    // OpenAI APIã‚­ãƒ¼ã¯å¸¸ã«å¿…è¦ï¼ˆChatCompletionç”¨ã€ãŠã‚ˆã³ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨TTSï¼‰
    if (!state.apiKey || !state.apiKey.startsWith("sk-")) {
      return false;
    }

    return true;
  }

  /**
   * ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’æ›´æ–°ã™ã‚‹ã€‚
   */
  function updateMicButtonState() {
    const isValid = validateApiKey();
    if (micButton) {
      micButton.disabled = !state.menuActive || !isValid || state.isRecording;
      if (!isValid && state.menuActive) {
        setChatStatus("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      } else if (isValid && state.menuActive && !state.isRecording) {
        setChatStatus("ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦éŸ³å£°å…¥åŠ›ã‚’é–‹å§‹");
      }
    }
  }

  /**
   * éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’OpenAI Whisper APIã«é€ä¿¡ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚
   */
  async function transcribeAudio(audioBlob) {
    if (!state.apiKey) {
      throw new Error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“");
    }

    const formData = new FormData();
    formData.append("file", audioBlob, "audio.webm");
    formData.append("model", "whisper-1");
    formData.append("language", "ja");

    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${state.apiKey}`,
      },
      body: formData,
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        `Whisper API error: ${response.status} - ${errorData.error?.message || response.statusText}`
      );
    }

    const data = await response.json();
    return data.text || "";
  }

  /**
   * ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’OpenAI ChatCompletion APIã«é€ä¿¡ã—ã¦AIå¿œç­”ã‚’å–å¾—ã™ã‚‹ã€‚
   * @param {string} userMessage - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
   * @returns {Promise<string>} AIã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
   */
  async function sendMessageToAI(userMessage) {
    if (!state.apiKey) {
      throw new Error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“");
    }

    // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    state.chatHistory.push({
      role: "user",
      content: userMessage,
    });

    // ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é…åˆ—ã‚’æ§‹ç¯‰
    const messages = [
      {
        role: "system",
        content: AI_CHARACTER_SYSTEM_PROMPT,
      },
      ...state.chatHistory,
    ];

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${state.apiKey}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: messages,
        temperature: 0.8,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        `ChatCompletion API error: ${response.status} - ${errorData.error?.message || response.statusText}`
      );
    }

    const data = await response.json();
    const aiMessage = data.choices?.[0]?.message?.content || "";

    if (!aiMessage) {
      throw new Error("AIå¿œç­”ãŒç©ºã§ã™");
    }

    // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    state.chatHistory.push({
      role: "assistant",
      content: aiMessage,
    });

    return aiMessage;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’OpenAI TTS APIã§éŸ³å£°ã«å¤‰æ›ã—ã¦å†ç”Ÿã™ã‚‹ã€‚
   * @param {string} text - éŸ³å£°åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @returns {Promise<void>}
   */
  async function textToSpeechOpenAI(text) {
    if (!state.apiKey) {
      throw new Error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“");
    }

    // æ—¢ã«å†ç”Ÿä¸­ã®éŸ³å£°ãŒã‚ã‚Œã°åœæ­¢
    if (state.audioElement) {
      state.audioElement.pause();
      state.audioElement = null;
    }

    const response = await fetch("https://api.openai.com/v1/audio/speech", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${state.apiKey}`,
      },
      body: JSON.stringify({
        model: OPENAI_TTS_CONFIG.model,
        voice: OPENAI_TTS_CONFIG.voice,
        input: text,
        speed: OPENAI_TTS_CONFIG.speed,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json().catch(() => ({}));
      throw new Error(
        `OpenAI TTS API error: ${response.status} - ${errorData.error?.message || response.statusText}`
      );
    }

    const audioArrayBuffer = await response.arrayBuffer();

    if (state.ttsAudioPlayer) {
      // éŸ³å£°å†ç”Ÿç›´å‰ã«éŸ³æºã‚’VRMãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ä½ç½®ã«å†ã‚¢ã‚¿ãƒƒãƒ
      const vrm = vrmManager?.getCurrentVrm?.();
      if (vrm?.scene) {
        state.ttsAudioPlayer.setAudioTarget(vrm.scene);
        logMessage("Info", "[ChatMenu] TTSéŸ³æºã‚’VRMãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ä½ç½®ã«å†ã‚¢ã‚¿ãƒƒãƒã—ã¾ã—ãŸ");
      }

      state.isSpeaking = true;
      // å£ãƒ‘ã‚¯é–‹å§‹
      if (vrmManager?.startLipSync) {
        vrmManager.startLipSync();
      }
      try {
        await state.ttsAudioPlayer.playArrayBuffer(audioArrayBuffer);
      } finally {
        state.isSpeaking = false;
        // å£ãƒ‘ã‚¯åœæ­¢
        if (vrmManager?.stopLipSync) {
          vrmManager.stopLipSync();
        }
      }
      return;
    }

    const audioBlob = new Blob([audioArrayBuffer], { type: "audio/mpeg" });
    const audioUrl = URL.createObjectURL(audioBlob);

    state.audioElement = new Audio(audioUrl);
    state.isSpeaking = true;

    state.audioElement.onended = () => {
      URL.revokeObjectURL(audioUrl);
      state.isSpeaking = false;
      state.audioElement = null;
    };

    state.audioElement.onerror = (error) => {
      logMessage("Error", "OpenAI audio playback error", { error: error });
      URL.revokeObjectURL(audioUrl);
      state.isSpeaking = false;
      state.audioElement = null;
    };

    await state.audioElement.play();
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’AIVIS TTS APIã§éŸ³å£°ã«å¤‰æ›ã—ã¦ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å†ç”Ÿã™ã‚‹ã€‚
   * @param {string} text - éŸ³å£°åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @returns {Promise<void>}
   */
  async function textToSpeechAIVIS(text) {
    if (!state.aivisApiKey) {
      throw new Error("Aivis APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“");
    }

    if (state.audioElement) {
      state.audioElement.pause();
      state.audioElement = null;
    }
    if (state.mediaSource) {
      try {
        if (state.mediaSource.readyState === "open") {
          state.mediaSource.endOfStream();
        }
      } catch (e) {
        // ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
      }
      state.mediaSource = null;
    }

    const response = await fetch("https://api.aivis-project.com/v1/tts/synthesize", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${state.aivisApiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model_uuid: AIVIS_TTS_CONFIG.model_uuid,
        text: text,
        use_ssml: AIVIS_TTS_CONFIG.use_ssml,
        use_volume_normalizer: AIVIS_TTS_CONFIG.use_volume_normalizer,
        output_format: AIVIS_TTS_CONFIG.output_format,
        leading_silence_seconds: AIVIS_TTS_CONFIG.leading_silence_seconds,
        trailing_silence_seconds: AIVIS_TTS_CONFIG.trailing_silence_seconds,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text().catch(() => "");
      throw new Error(`AIVIS TTS API error: ${response.status} - ${errorText}`);
    }

    if (state.ttsAudioPlayer) {
      // éŸ³å£°å†ç”Ÿç›´å‰ã«éŸ³æºã‚’VRMãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ä½ç½®ã«å†ã‚¢ã‚¿ãƒƒãƒ
      const vrm = vrmManager?.getCurrentVrm?.();
      if (vrm?.scene) {
        state.ttsAudioPlayer.setAudioTarget(vrm.scene);
        logMessage("Info", "[ChatMenu] TTSéŸ³æºã‚’VRMãƒ¢ãƒ‡ãƒ«ã®ç¾åœ¨ä½ç½®ã«å†ã‚¢ã‚¿ãƒƒãƒã—ã¾ã—ãŸ (AIVIS)");
      }

      const audioArrayBuffer = await response.arrayBuffer();
      state.isSpeaking = true;
      // å£ãƒ‘ã‚¯é–‹å§‹
      if (vrmManager?.startLipSync) {
        vrmManager.startLipSync();
      }
      try {
        await state.ttsAudioPlayer.playArrayBuffer(audioArrayBuffer);
      } finally {
        state.isSpeaking = false;
        // å£ãƒ‘ã‚¯åœæ­¢
        if (vrmManager?.stopLipSync) {
          vrmManager.stopLipSync();
        }
      }
      return;
    }

    const mediaSource = self.MediaSource
      ? new self.MediaSource()
      : new self.ManagedMediaSource();
    state.mediaSource = mediaSource;

    const audio = new Audio(URL.createObjectURL(mediaSource));
    audio.disableRemotePlayback = true;
    state.audioElement = audio;
    state.isSpeaking = true;

    audio.onended = () => {
      state.isSpeaking = false;
      state.audioElement = null;
      state.mediaSource = null;
    };

    audio.onerror = (error) => {
      logMessage("Error", "AIVIS audio playback error", { error: error });
      state.isSpeaking = false;
      state.audioElement = null;
      state.mediaSource = null;
    };

    audio.play().catch(error => logMessage("Error", "AIVIS audio play error", { error: error }));

    await new Promise((resolve, reject) => {
      mediaSource.addEventListener(
        "sourceopen",
        async () => {
          try {
            const sourceBuffer = mediaSource.addSourceBuffer("audio/mpeg");

            const waitForIdle = () =>
              sourceBuffer.updating
                ? new Promise((r) =>
                    sourceBuffer.addEventListener("updateend", r, { once: true })
                  )
                : Promise.resolve();

            const waitForIdleCompletely = async () => {
              while (sourceBuffer.updating) {
                await waitForIdle();
                await new Promise((r) => setTimeout(r, 0));
              }
            };

            const reader = response.body.getReader();

            for (;;) {
              const { value, done } = await reader.read();

              if (done) {
                await waitForIdleCompletely();
                try {
                  mediaSource.endOfStream();
                } catch (error) {
                  if (error.name === "InvalidStateError" && sourceBuffer.updating) {
                    await waitForIdleCompletely();
                    mediaSource.endOfStream();
                  } else {
                    throw error;
                  }
                }
                resolve();
                break;
              }

              await waitForIdle();
              await new Promise((r) => setTimeout(r, 0));
              sourceBuffer.appendBuffer(value);
            }
          } catch (error) {
            reject(error);
          }
        },
        { once: true }
      );
    });
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›ã—ã¦å†ç”Ÿã™ã‚‹ã€‚
   * Aivis APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯AIVIS TTSã‚’ä½¿ç”¨ã—ã€ãã‚Œä»¥å¤–ã¯OpenAI TTSã‚’ä½¿ç”¨ã™ã‚‹ã€‚
   * @param {string} text - éŸ³å£°åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
   * @returns {Promise<void>}
   */
  async function textToSpeech(text) {
    // Aivis APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯AIVIS TTSã‚’ä½¿ç”¨
    if (state.aivisApiKey) {
      return await textToSpeechAIVIS(text);
    } else {
      return await textToSpeechOpenAI(text);
    }
  }

  /**
   * éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã€‚
   * @param {boolean} isBottomChat - Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆãƒœã‚¿ãƒ³ã‹ã‚‰ã®å‘¼ã³å‡ºã—ã‹ã©ã†ã‹
   */
  async function startRecording(isBottomChat = false) {
    if (state.isRecording) {
      return;
    }

    logMessage("Info", "[ChatMenu] ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³æŠ¼ä¸‹", {
      context: isBottomChat ? "bottomChat" : "desktopMenu",
    });

    // ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã«ã€Œã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    if (actionMenu && typeof actionMenu.executeComeHereFrontAction === 'function') {
      try {
        await actionMenu.executeComeHereFrontAction();
        logMessage("Info", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ", {
          context: isBottomChat ? "bottomChat" : "desktopMenu",
        });
      } catch (error) {
        logMessage("Warn", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", {
          context: isBottomChat ? "bottomChat" : "desktopMenu",
          error: error?.message ?? String(error),
        });
      }
    }

    await ensureAudioContextUnlocked("startRecording");

    // éŒ²éŸ³é–‹å§‹å…ƒã‚’è¨˜éŒ²
    state.recordingSource = isBottomChat ? "bottomChat" : "settingsMenu";

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      state.audioChunks = [];

      // MediaRecorderã®è¨­å®š
      const options = { mimeType: "audio/webm" };
      state.mediaRecorder = new MediaRecorder(stream, options);

      state.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          state.audioChunks.push(event.data);
        }
      };

      state.mediaRecorder.onstop = async () => {
        // éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream.getTracks().forEach((track) => track.stop());

        const audioBlob = new Blob(state.audioChunks, { type: "audio/webm" });
        state.audioChunks = [];
        const isBottomChat = state.recordingSource === "bottomChat";

        setChatStatus("éŸ³å£°ã‚’å‡¦ç†ä¸­...");

        try {
          const transcription = await transcribeAudio(audioBlob);
          if (transcription) {
            if (isBottomChat) {
              // Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã®å ´åˆã€å…¥åŠ›æ¬„ã«èªè­˜ã—ãŸæ–‡å­—ã‚’è¡¨ç¤ºï¼ˆè‡ªå‹•é€ä¿¡ã¯ã—ãªã„ï¼‰
              if (bottomChatTextInput) {
                bottomChatTextInput.value = transcription;
              }
              setChatStatus("éŸ³å£°èªè­˜å®Œäº†");
            } else {
              // è¨­å®šç”»é¢ã®ãƒãƒ£ãƒƒãƒˆã®å ´åˆã€å¾“æ¥é€šã‚Šã®å‡¦ç†
              appendTranscript(transcription, "user");

              // AIã«é€ä¿¡ã—ã¦å¿œç­”ã‚’å–å¾—
              setChatStatus("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...");
              state.isProcessing = true;
              try {
                const aiResponse = await sendMessageToAI(transcription);
                appendTranscript(aiResponse, "ai");

                // TTSã§éŸ³å£°å†ç”Ÿ
                setChatStatus("éŸ³å£°ã‚’ç”Ÿæˆä¸­...");
                try {
                  await textToSpeech(aiResponse);
                  setChatStatus("å®Œäº†");
                } catch (ttsError) {
                  logMessage("Error", "TTS error", { error: ttsError });
                  setChatStatus(`éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ${ttsError.message}`);
                }
              } catch (aiError) {
                logMessage("Error", "AI response error", { error: aiError });
                setChatStatus(`AIã‚¨ãƒ©ãƒ¼: ${aiError.message}`);
              } finally {
                state.isProcessing = false;
              }
            }
          } else {
            setChatStatus("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ");
          }
        } catch (error) {
          logMessage("Error", "Transcription error", { error: error });
          setChatStatus(`ã‚¨ãƒ©ãƒ¼: ${error.message}`);
        } finally {
          state.isRecording = false;
          state.recordingSource = null;
          updateMicButtonState();
          updateBottomMicButtonState();
          if (micButton) {
            micButton.textContent = "ğŸ¤ ãƒã‚¤ã‚¯";
          }
          if (bottomChatMicButton) {
            bottomChatMicButton.innerHTML = '<i class="fas fa-microphone"></i>';
          }
        }
      };

      state.mediaRecorder.start();
      state.isRecording = true;
      setChatStatus("éŒ²éŸ³ä¸­... (ã‚‚ã†ä¸€åº¦æŠ¼ã™ã¨åœæ­¢)");
      if (micButton) {
        micButton.textContent = "â¹ï¸ åœæ­¢";
        micButton.disabled = false;
      }
      if (bottomChatMicButton) {
        bottomChatMicButton.innerHTML = '<i class="fas fa-stop"></i>';
      }
    } catch (error) {
      const normalizedError = normalizeMicPermissionError(error);
      logMessage("Error", "Recording error", { error: normalizedError });
      if (isMicPermissionError(normalizedError)) {
        setChatStatus(MIC_PERMISSION_ERROR_MESSAGE);
      } else {
        setChatStatus(`ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼: ${normalizedError.message}`);
      }
      state.isRecording = false;
      updateMicButtonState();
    }
  }

  /**
   * éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹ã€‚
   */
  function stopRecording() {
    if (!state.isRecording || !state.mediaRecorder) {
      return;
    }

    state.mediaRecorder.stop();
    setChatStatus("éŒ²éŸ³ã‚’åœæ­¢ã—ã¾ã—ãŸ");
  }

  /**
   * ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚
   */
  function handleMicButtonClick() {
    if (!validateApiKey()) {
      setChatStatus("æœ‰åŠ¹ãªOpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    if (state.isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  }

  /**
   * APIã‚­ãƒ¼å…¥åŠ›æ¬„ã®å¤‰æ›´ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚
   * APIã‚­ãƒ¼ã‚’sessionStorageã«ä¿å­˜ã™ã‚‹ã€‚
   */
  function handleApiKeyChange() {
    // sessionStorageã«APIã‚­ãƒ¼ã‚’ä¿å­˜
    if (apiKeyInput?.value) {
      sessionStorage.setItem("openai_api_key", apiKeyInput.value);
    } else {
      sessionStorage.removeItem("openai_api_key");
    }
    if (aivisApiKeyInput?.value) {
      sessionStorage.setItem("aivis_api_key", aivisApiKeyInput.value);
    } else {
      sessionStorage.removeItem("aivis_api_key");
    }

    updateMicButtonState();
    updateSendButtonState();
    updateBottomMicButtonState();
    updateBottomSendButtonState();
  }

  /**
   * é€ä¿¡ãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’æ›´æ–°ã™ã‚‹ã€‚
   */
  function updateSendButtonState() {
    if (!sendButton) {
      return;
    }
    const isValid = validateApiKey();
    sendButton.disabled = !state.menuActive || !isValid || state.isProcessing || state.isRecording;
  }

  /**
   * Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¨ãƒªã‚¢ã«ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹ã€‚
   * @param {string} message - è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
   */
  function addBottomChatSystemMessage(message) {
    if (!bottomChatMessages) {
      return;
    }
    const systemEntry = `ã‚·ã‚¹ãƒ†ãƒ ï¼š${message}\n`;
    bottomChatMessages.textContent += systemEntry;
    // è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
    bottomChatMessages.scrollTop = bottomChatMessages.scrollHeight;
  }

  /**
   * Webç”»é¢ä¸‹éƒ¨ã®ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’æ›´æ–°ã™ã‚‹ã€‚
   * APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã‚‚æŠ¼ã›ã‚‹ã‚ˆã†ã«ã—ã€æŠ¼ã•ã‚ŒãŸæ™‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
   */
  function updateBottomMicButtonState() {
    if (!bottomChatMicButton) {
      return;
    }
    // éŒ²éŸ³ä¸­ã®ã¿ç„¡åŠ¹åŒ–
    bottomChatMicButton.disabled = state.isRecording;
  }

  /**
   * Webç”»é¢ä¸‹éƒ¨ã®é€ä¿¡ãƒœã‚¿ãƒ³ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’æ›´æ–°ã™ã‚‹ã€‚
   * APIã‚­ãƒ¼ãŒæœªå…¥åŠ›ã§ã‚‚æŠ¼ã›ã‚‹ã‚ˆã†ã«ã—ã€æŠ¼ã•ã‚ŒãŸæ™‚ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã™ã‚‹ã€‚
   */
  function updateBottomSendButtonState() {
    if (!bottomChatSendButton) {
      return;
    }
    // å‡¦ç†ä¸­ã¾ãŸã¯éŒ²éŸ³ä¸­ã®ã¿ç„¡åŠ¹åŒ–
    bottomChatSendButton.disabled = state.isProcessing || state.isRecording;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ã€‚
   */
  async function handleSendMessage() {
    if (!validateApiKey()) {
      setChatStatus("æœ‰åŠ¹ãªOpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    if (!textInput || !textInput.value.trim()) {
      setChatStatus("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    // é€ä¿¡ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã«ã€Œã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    if (actionMenu && typeof actionMenu.executeComeHereFrontAction === 'function') {
      try {
        await actionMenu.executeComeHereFrontAction();
        logMessage("Info", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ", {
          context: "sendMessage",
        });
      } catch (error) {
        logMessage("Warn", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", {
          context: "sendMessage",
          error: error?.message ?? String(error),
        });
      }
    }

    const userMessage = textInput.value.trim();
    textInput.value = "";

    // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    appendTranscript(userMessage, "user");
    setChatStatus("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...");
    state.isProcessing = true;
    updateSendButtonState();

    try {
      const aiResponse = await sendMessageToAI(userMessage);
      appendTranscript(aiResponse, "ai");

      // TTSã§éŸ³å£°å†ç”Ÿ
      setChatStatus("éŸ³å£°ã‚’ç”Ÿæˆä¸­...");
      try {
        await textToSpeech(aiResponse);
        setChatStatus("å®Œäº†");
      } catch (ttsError) {
        logMessage("Error", "TTS error", { error: ttsError });
        setChatStatus(`éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ${ttsError.message}`);
      }
    } catch (error) {
      logMessage("Error", "AI response error", { error: error });
      setChatStatus(`ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    } finally {
      state.isProcessing = false;
      updateSendButtonState();
    }
  }

  /**
   * Webç”»é¢ä¸‹éƒ¨ã®ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚
   */
  function handleBottomMicButtonClick() {
    if (!validateApiKey()) {
      addBottomChatSystemMessage("è¨­å®šç”»é¢ã§APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    if (state.isRecording) {
      stopRecording();
    } else {
      startRecording(true); // true ã‚’æ¸¡ã—ã¦Webç”»é¢ä¸‹éƒ¨ã‹ã‚‰ã®å‘¼ã³å‡ºã—ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã™
    }
  }

  /**
   * Webç”»é¢ä¸‹éƒ¨ã®é€ä¿¡ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚
   */
  async function handleBottomSendMessage() {
    if (!validateApiKey()) {
      addBottomChatSystemMessage("è¨­å®šç”»é¢ã§APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    if (!bottomChatTextInput || !bottomChatTextInput.value.trim()) {
      addBottomChatSystemMessage("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„");
      return;
    }

    // é€ä¿¡ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã«ã€Œã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ
    if (actionMenu && typeof actionMenu.executeComeHereFrontAction === 'function') {
      try {
        await actionMenu.executeComeHereFrontAction();
        logMessage("Info", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ", {
          context: "bottomSendMessage",
        });
      } catch (error) {
        logMessage("Warn", "[ChatMenu] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", {
          context: "bottomSendMessage",
          error: error?.message ?? String(error),
        });
      }
    }

    const userMessage = bottomChatTextInput.value.trim();
    bottomChatTextInput.value = "";

    setChatStatus("AIãŒå¿œç­”ã‚’ç”Ÿæˆä¸­...");
    state.isProcessing = true;
    updateBottomSendButtonState();

    try {
      const aiResponse = await sendMessageToAI(userMessage);
      // AIå¿œç­”ã®ã¿ã‚’Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢ã«è¿½åŠ 
      if (bottomChatMessages) {
        const aiEntry = `${AI_NAME}ï¼š${aiResponse}\n`;
        bottomChatMessages.textContent += aiEntry;
        // è‡ªå‹•ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
        bottomChatMessages.scrollTop = bottomChatMessages.scrollHeight;
      }
      // è¨­å®šç”»é¢ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚‚è¿½åŠ 
      appendTranscript(userMessage, "user");
      appendTranscript(aiResponse, "ai");

      // TTSã§éŸ³å£°å†ç”Ÿ
      setChatStatus("éŸ³å£°ã‚’ç”Ÿæˆä¸­...");
      try {
        await textToSpeech(aiResponse);
        setChatStatus("å®Œäº†");
      } catch (ttsError) {
        logMessage("Error", "TTS error", { error: ttsError });
        setChatStatus(`éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: ${ttsError.message}`);
      }
    } catch (error) {
      logMessage("Error", "AI response error", { error: error });
      setChatStatus(`ã‚¨ãƒ©ãƒ¼: ${error.message}`);
    } finally {
      state.isProcessing = false;
      updateBottomSendButtonState();
    }
  }

  /**
   * ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ãŸéš›ã®ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã€‚
   * NOTE: ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒãƒ£ãƒƒãƒˆå°‚ç”¨ã®ãŸã‚ã€é€šå¸¸ã¯å¸¸ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ï¼ˆtrueï¼‰ã§ã™ã€‚
   * ã“ã®é–¢æ•°ã¯äº’æ›æ€§ã®ãŸã‚ã«æ®‹ã•ã‚Œã¦ã„ã¾ã™ãŒã€å®Ÿéš›ã«ã¯ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚
   */
  function setMenuActive(active) {
    state.menuActive = !!active;
    if (!state.menuActive) {
      // ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ãŸã‚‰éŒ²éŸ³ã‚’åœæ­¢
      if (state.isRecording) {
        stopRecording();
      }
      // éŸ³å£°å†ç”Ÿã‚’åœæ­¢
      if (state.audioElement) {
        state.audioElement.pause();
        state.audioElement = null;
        state.isSpeaking = false;
      }
      // MediaSourceã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (state.mediaSource) {
        try {
          if (state.mediaSource.readyState === "open") {
            state.mediaSource.endOfStream();
          }
        } catch (e) {
          // ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        }
        state.mediaSource = null;
      }
      if (state.ttsAudioPlayer) {
        state.ttsAudioPlayer.stop();
        state.isSpeaking = false;
      }
      setChatStatus("");
      if (chatTranscript) {
        chatTranscript.textContent = "";
      }
      // ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢
      state.chatHistory = [];
      state.isProcessing = false;
      return;
    }
    updateMicButtonState();
    updateSendButtonState();
  }

  /**
   * VRM èª­ã¿è¾¼ã¿å®Œäº†æ™‚ã®å‡¦ç†ã€‚
   */
  function handleVrmReady() {
    if (state.menuActive) {
      updateMicButtonState();
    }
  }

  /**
   * VRç”¨: ç¾åœ¨ã®APIã‚­ãƒ¼ã‚’å–å¾—ã™ã‚‹ã€‚
   */
  function getApiKey() {
    return state.apiKey;
  }

  /**
   * VRç”¨: éŒ²éŸ³ä¸­ã‹ã©ã†ã‹ã‚’å–å¾—ã™ã‚‹ã€‚
   */
  function isRecording() {
    return state.isRecording;
  }

  /**
   * VRç”¨: éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã€‚
   * @param {Function} onTranscriptCallback - ãƒ†ã‚­ã‚¹ãƒˆèªè­˜å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ (text: string) => void
   * @param {Function} onErrorCallback - ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ (error: Error) => void
   */
  async function startVrRecording(onTranscriptCallback, onErrorCallback) {
    if (state.isRecording) {
      return;
    }

    logMessage("Info", "[ChatMenu][VR] ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³æŠ¼ä¸‹", {
      context: "vrMenu",
    });

    if (!state.apiKey) {
      onErrorCallback?.(new Error("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"));
      return;
    }

    if (actionMenu && typeof actionMenu.executeComeHereFrontAction === "function") {
      try {
        await actionMenu.executeComeHereFrontAction();
        logMessage("Info", "[ChatMenu][VR] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ", {
          context: "vrMenu",
        });
      } catch (error) {
        logMessage("Warn", "[ChatMenu][VR] ã“ã£ã¡ã«ãã‚‹(æ­£é¢)ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼", {
          context: "vrMenu",
          error: error?.message ?? String(error),
        });
      }
    }

    await ensureAudioContextUnlocked("startVrRecording");

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      state.audioChunks = [];

      const options = { mimeType: "audio/webm" };
      state.mediaRecorder = new MediaRecorder(stream, options);

      state.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          state.audioChunks.push(event.data);
        }
      };

      state.mediaRecorder.onstop = async () => {
        // éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
        stream.getTracks().forEach((track) => track.stop());

        const audioBlob = new Blob(state.audioChunks, { type: "audio/webm" });
        state.audioChunks = [];

        try {
          const transcription = await transcribeAudio(audioBlob);
          // ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã¶å‰ã«éŒ²éŸ³çŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
          state.isRecording = false;

          if (transcription) {
            // Webç‰ˆã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã«ã‚‚è¿½åŠ 
            appendTranscript(transcription, "user");

            // AIã«é€ä¿¡ã—ã¦å¿œç­”ã‚’å–å¾—
            state.isProcessing = true;
            try {
              const aiResponse = await sendMessageToAI(transcription);
              appendTranscript(aiResponse, "ai");

              // VRã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨AIå¿œç­”ã®ä¸¡æ–¹ã‚’é€šçŸ¥ï¼ˆéŸ³å£°å†ç”Ÿå‰ã«å³åº§ã«è¡¨ç¤ºï¼‰
              onTranscriptCallback?.({ user: transcription, ai: aiResponse });

              // TTSã§éŸ³å£°å†ç”Ÿ
              try {
                await textToSpeech(aiResponse);
              } catch (ttsError) {
                logMessage("Error", "VR TTS error", { error: ttsError });
              }
            } catch (aiError) {
              logMessage("Error", "VR AI response error", { error: aiError });
              onErrorCallback?.(aiError);
            } finally {
              state.isProcessing = false;
            }
          } else {
            onErrorCallback?.(new Error("éŸ³å£°ã‚’èªè­˜ã§ãã¾ã›ã‚“ã§ã—ãŸ"));
          }
        } catch (error) {
          logMessage("Error", "VR Transcription error", { error: error });
          state.isRecording = false;
          onErrorCallback?.(error);
        }
      };

      state.mediaRecorder.start();
      state.isRecording = true;
    } catch (error) {
      const normalizedError = normalizeMicPermissionError(error);
      logMessage("Error", "VR Recording error", { error: normalizedError });
      state.isRecording = false;
      onErrorCallback?.(normalizedError);
    }
  }

  /**
   * VRç”¨: éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹ã€‚
   */
  function stopVrRecording() {
    if (!state.isRecording || !state.mediaRecorder) {
      return;
    }
    state.mediaRecorder.stop();
  }

  // ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã®è¨­å®š
  micButton?.addEventListener("click", handleMicButtonClick);
  apiKeyInput?.addEventListener("input", handleApiKeyChange);
  aivisApiKeyInput?.addEventListener("input", handleApiKeyChange);
  sendButton?.addEventListener("click", handleSendMessage);

  // Webç”»é¢ä¸‹éƒ¨ã®ãƒãƒ£ãƒƒãƒˆè¦ç´ ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼
  bottomChatMicButton?.addEventListener("click", handleBottomMicButtonClick);
  bottomChatSendButton?.addEventListener("click", handleBottomSendMessage);

  // åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
  updateBottomMicButtonState();
  updateBottomSendButtonState();

  /**
   * VRç”¨ã®ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã‚’å–å¾—ã—ã¦å†ç”Ÿã™ã‚‹ã€‚
   * @returns {Promise<void>}
   */
  async function playSampleAudio() {
    if (!state.ttsAudioPlayer) {
      throw new Error("TTSãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“");
    }

    const response = await fetch("./mp3/aivis_sample.mp3");
    if (!response.ok) {
      throw new Error(`ã‚µãƒ³ãƒ—ãƒ«éŸ³å£°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ (${response.status})`);
    }
    const buffer = await response.arrayBuffer();
    await state.ttsAudioPlayer.playArrayBuffer(buffer);
  }

  return {
    setMenuActive,
    handleVrmReady,
    // VRç”¨API
    getApiKey,
    isRecording,
    startVrRecording,
    stopVrRecording,
    playSampleAudio,
  };
}
